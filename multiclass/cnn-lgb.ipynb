{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.optimizers as opt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, MaxPooling1D, BatchNormalization, Activation, Layer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.initializers import  RandomNormal, Constant\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, plot_metric\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all kinds of cats:  ['bljfm', 'bom', 'dlm', 'fksm', 'jjc', 'jm', 'lm', 'md', 'mgbwm', 'mmm', 'mym', 'nnm', 'xmly', 'yjc', 'zem']\n",
      "bljfm :  258\n",
      "bom :  257\n",
      "dlm :  222\n",
      "fksm :  222\n",
      "jjc :  246\n",
      "jm :  232\n",
      "lm :  270\n",
      "md :  258\n",
      "mgbwm :  235\n",
      "mmm :  212\n",
      "mym :  222\n",
      "nnm :  200\n",
      "xmly :  204\n",
      "yjc :  234\n",
      "zem :  235\n",
      "total cat imgs:  3507\n"
     ]
    }
   ],
   "source": [
    "path = \"../img_sub/cat\"\n",
    "dirlist = os.listdir(path)\n",
    "catPath = [os.path.join(path, dirname) for dirname in dirlist]\n",
    "\n",
    "total_img_num = sum(map(len,map(os.listdir, catPath)))\n",
    "print('all kinds of cats: ', dirlist)\n",
    "for i in range(len(catPath)):\n",
    "    print(dirlist[i], ': ', len(os.listdir(catPath[i])))\n",
    "print('total cat imgs: ', total_img_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 2\n",
    "IMG_HEIGHT = 116\n",
    "IMG_WIDTH = 116\n",
    "split = 0.2\n",
    "classNum = len(dirlist)\n",
    "total_val = total_img_num * split\n",
    "total_train = total_img_num * (1 - split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,rotation_range=40, # Angle, 0-180\n",
    "    width_shift_range=0.2, # horizontal shifting\n",
    "    height_shift_range=0.2, # vertical shifting\n",
    "    shear_range=0.2, # Shearing\n",
    "    zoom_range=0.2, # Zooming\n",
    "    horizontal_flip=True, # Flipping\n",
    "    validation_split=split\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,rotation_range=40, # Angle, 0-180\n",
    "    width_shift_range=0.2, # horizontal shifting\n",
    "    height_shift_range=0.2, # vertical shifting\n",
    "    shear_range=0.2, # Shearing\n",
    "    zoom_range=0.2, # Zooming\n",
    "    horizontal_flip=True, # Flipping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2811 images belonging to 15 classes.\n",
      "Found 696 images belonging to 15 classes.\n",
      "Train set shape:  (2811,)\n",
      "Validation/Test set shape:  (696,)\n"
     ]
    }
   ],
   "source": [
    "# Load images from the disk, applies rescaling, and resizes the images\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ") # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ") # set as validation data\n",
    "\n",
    "print(\"Train set shape: \", train_generator.classes.shape)\n",
    "print(\"Validation/Test set shape: \", validation_generator.classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cq-ecloud-12\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\cq-ecloud-12\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\cq-ecloud-12\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../multiclass/f_3355_60.180.h5')\n",
    "model.load_weights('../multiclass/f_3355_60.120_weights_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "279/280 [============================>.] - ETA: 1s - loss: 2.4851 - acc: 0.1848Epoch 1/2\n",
      "280/280 [==============================] - 460s 2s/step - loss: 2.4848 - acc: 0.1842 - val_loss: 2.2605 - val_acc: 0.2529\n",
      "Epoch 2/2\n",
      "279/280 [============================>.] - ETA: 1s - loss: 2.1747 - acc: 0.2866Epoch 1/2\n",
      "280/280 [==============================] - 464s 2s/step - loss: 2.1727 - acc: 0.2874 - val_loss: 2.0925 - val_acc: 0.3132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c62030d808>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = total_train // batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = total_val // batch_size     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1_layer_model = Model(inputs=a.input,\n",
    "                           outputs=a.get_layer('dense1').output)\n",
    "\n",
    "dense1_output = dense1_layer_model.predict(train_generator)\n",
    "dense1_val = dense1_layer_model.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6108786  -0.3532786  -1.2052345  ...  0.10455371 -1.4605719\n",
      "   0.04596918]\n",
      " [-0.5341646  -1.2753508   0.04842879 ...  1.6989881  -0.8268048\n",
      "  -0.722327  ]\n",
      " [-0.6747088  -0.38915032 -1.4430646  ...  0.9178795  -1.285453\n",
      "  -0.7232323 ]\n",
      " ...\n",
      " [-0.79202884 -0.04390685 -1.2515142  ...  0.93111014 -1.5253102\n",
      "  -1.0547165 ]\n",
      " [-0.73487765 -0.6647993  -0.7360235  ...  1.385342   -0.74194056\n",
      "  -1.7325449 ]\n",
      " [-1.227324   -1.0708028  -1.3834912  ... -0.12302708 -1.8690329\n",
      "  -0.72714776]]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8  8  8  8  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "x_train = dense1_output\n",
    "y_train = train_generator.classes\n",
    "x_test = dense1_val\n",
    "y_test = validation_generator.classes\n",
    "\n",
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.929598\n",
      "Will train until validation_0-merror hasn't improved in 40 rounds.\n",
      "[1]\tvalidation_0-merror:0.926724\n",
      "[2]\tvalidation_0-merror:0.925287\n",
      "[3]\tvalidation_0-merror:0.933908\n",
      "[4]\tvalidation_0-merror:0.926724\n",
      "[5]\tvalidation_0-merror:0.918103\n",
      "[6]\tvalidation_0-merror:0.920977\n",
      "[7]\tvalidation_0-merror:0.923851\n",
      "[8]\tvalidation_0-merror:0.920977\n",
      "[9]\tvalidation_0-merror:0.91523\n",
      "[10]\tvalidation_0-merror:0.91092\n",
      "[11]\tvalidation_0-merror:0.918103\n",
      "[12]\tvalidation_0-merror:0.918103\n",
      "[13]\tvalidation_0-merror:0.918103\n",
      "[14]\tvalidation_0-merror:0.91954\n",
      "[15]\tvalidation_0-merror:0.922414\n",
      "[16]\tvalidation_0-merror:0.91954\n",
      "[17]\tvalidation_0-merror:0.91954\n",
      "[18]\tvalidation_0-merror:0.91954\n",
      "[19]\tvalidation_0-merror:0.918103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=20, n_jobs=1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb = xgb.XGBClassifier(max_depth = 3,  learning_rate=0.01,n_estimators=20)\n",
    "xb.fit(x_train, y_train,eval_set = [(x_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26752045535396657\n",
      "0.08908045977011494\n"
     ]
    }
   ],
   "source": [
    "print(xb.score(x_train,y_train))\n",
    "print(xb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\" : \"softmax\",\n",
    "          \"num_class\" : 15,\n",
    "          \"num_leaves\" : 50,\n",
    "          \"max_depth\": -1,\n",
    "          \"learning_rate\" : 0.01,\n",
    "          \"bagging_fraction\" : 0.9,  # subsample\n",
    "          \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"verbosity\" : -1,\n",
    "          \"metric\" : \"softmax\"\n",
    "}\n",
    "\n",
    "classifier_params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'num_leaves' : 31,\n",
    "    'max_depth' : -1,\n",
    "    'learning_rate' : 0.1,\n",
    "    'n_estimators' : 100,\n",
    "    'subsample_for_bin' : 200000,\n",
    "    'objective' : 'softmax',\n",
    "    'class_weight' : None,\n",
    "    'min_split_gain' : 0.0,\n",
    "    'min_child_weight' : 0.001,\n",
    "    'min_child_samples' : 20,\n",
    "    'subsample' : 1.0,\n",
    "    'subsample_freq' : 0,\n",
    "    'colsample_bytree' : 1.0,\n",
    "    'reg_alpha' : 0.0,\n",
    "    'reg_lambda' : 0.0,\n",
    "    'random_state' : '10927',\n",
    "    'n_jobs' : -1,\n",
    "    'silent' : True,\n",
    "    'importance_type' : 'split'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = lgb.Dataset(x_train, label = y_train)\n",
    "dataset.construct()\n",
    "vali = dataset.create_valid(x_test, label = y_test)\n",
    "vali.construct()\n",
    "print(dataset.num_data())\n",
    "print(vali.num_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_hist = lgb.cv(params, train_set = dataset)\n",
    "# trained_model = lgb.train(params, train_set = dataset)\n",
    "trained_model = lgb.train(params, train_set = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=20,\n",
    "    max_depth=50,\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=30,\n",
    "    subsample_for_bin=10,\n",
    "    objective='softmax',\n",
    "    class_weight=None,\n",
    "    min_split_gain=0.0,\n",
    "    min_child_weight=0.001,\n",
    "    min_child_samples=20,\n",
    "    subsample=1.0,\n",
    "    subsample_freq=0,\n",
    "    colsample_bytree=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state='10927',\n",
    "    n_jobs=-1,\n",
    "    silent=True,\n",
    "    importance_type='split'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = 0\n",
    "for i in range(len(result)):\n",
    "    if result[i] == y_test[i]:\n",
    "        corr += 1\n",
    "print(corr*1.0/len(result))\n",
    "print(y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
