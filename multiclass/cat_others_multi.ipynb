{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fast.ai \n",
    "Practical Deep Learning for Coders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.optimizers as opt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, MaxPooling1D, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path & total number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./img_sub/cat\"\n",
    "dirlist = os.listdir(path)\n",
    "catPath = [os.path.join(path, dirname) for dirname in dirlist]\n",
    "# path_noncat = os.path.join(path, 'no_cat')\n",
    "\n",
    "\n",
    "# train_dir = 'C:/Users/cs623/.keras/datasets/cats_and_dogs_filtered/train'\n",
    "# validation_dir = 'C:/Users/cs623/.keras/datasets/cats_and_dogs_filtered/validation'\n",
    "# train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "# train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "# validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "# validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_img_num = sum(map(len,map(os.listdir, catPath)))\n",
    "print('all kinds of cats: ', dirlist)\n",
    "for i in range(len(catPath)):\n",
    "    print(dirlist[i], ': ', len(os.listdir(catPath[i])))\n",
    "print('total cat imgs: ', total_img_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 60\n",
    "IMG_HEIGHT = 116\n",
    "IMG_WIDTH = 116\n",
    "split = 0.2\n",
    "classNum = len(dirlist)\n",
    "total_val = total_img_num * split\n",
    "total_train = total_img_num * (1 - split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,rotation_range=40, # Angle, 0-180\n",
    "    width_shift_range=0.2, # horizontal shifting\n",
    "    height_shift_range=0.2, # vertical shifting\n",
    "    shear_range=0.2, # Shearing\n",
    "    zoom_range=0.2, # Zooming\n",
    "    horizontal_flip=True, # Flipping\n",
    "    validation_split=split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from the disk, applies rescaling, and resizes the images\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ") # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ") # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_train, sample_label_train = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImg(img):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for i, a in zip(img, axes):\n",
    "        a.imshow(i)\n",
    "        a.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImg(sample_img_train[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGNet = Sequential([\n",
    "    Conv2D(64, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3), ),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(classNum, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3), name = 'cov1'),\n",
    "    Activation('relu', name = 'act1'),\n",
    "    Conv2D(32, 3, name = 'cov2'),\n",
    "    Activation('relu', name = 'act2'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name = 'maxpool1'),\n",
    "    Dropout(0.25, name = 'drop1'),\n",
    "    Conv2D(64, 5, padding='same', name = 'cov3'),\n",
    "    Activation('relu', name = 'act3'),\n",
    "    Conv2D(64, 5, name = 'cov4'),\n",
    "    Activation('relu', name = 'act4'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name = 'maxpool2'),\n",
    "    Dropout(0.25, name = 'drop2'),\n",
    "    Flatten(name = 'flatten'),\n",
    "    Dense(512, name = 'dense1'),\n",
    "    Activation('relu', name = 'act5'),\n",
    "    Dropout(0.5, name = 'drop3'),\n",
    "    Dense(classNum, name = 'dense2'),\n",
    "    Activation('softmax', name = 'act6')\n",
    "])\n",
    "# 0.44-0.47 之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "rms = RMSprop(learning_rate=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'],  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "    code from http://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "    \"\"\"\n",
    "    from tensorflow.python.client import device_lib as _device_lib\n",
    "    local_device_protos = _device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU' or x.device_type == 'CPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./multiclass/f_3355_60.180_weights_1.h5')\n",
    "model.save('./multiclass/f_3355_60.180.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.load_weights('./multiclass/f_3355_60.120_weights_1.h5')\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = total_train // batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = total_val // batch_size     \n",
    "    )\n",
    "model.save_weights('./multiclass/f_3355_60.180_weights_1.h5')\n",
    "# model.save('3355_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionNet():\n",
    "    x_input = Input(shape = (116, 116, 3))\n",
    "    x = Conv2D(32, 3, padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3))(x_input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32,3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x1 = Conv2D(64, 5, padding='same')(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv2D(64, 5)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(64, 5, padding='same')(x)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = Conv2D(64, 5)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x = concatenate([x1, x2], axis = -1)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(521)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(classNum)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "\n",
    "    model = Model(inputs = x_input, outputs = x, name = 'tryInception')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep = InceptionNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep.compile(optimizer=sgd,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'],  \n",
    "             )\n",
    "incep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(incep, 'simplified_inception.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = incep.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = total_train // batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = total_val // batch_size     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep.save_weights('./multiclass/incp_3355_120_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
