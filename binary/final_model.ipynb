{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import model_from_yaml\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C://Users//cs623//Docs//GitHub//cat-recognition//img\"\n",
    "path_dog = os.path.join(path, 'cat')\n",
    "path_nodog = os.path.join(path, 'no_cat')\n",
    "class_names = ['cat', 'no_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "total images: 31911\nnumber of training data: 25528.8\nnumber of validation: 6382.200000000001\n"
    }
   ],
   "source": [
    "total_img_num = 0\n",
    "split = 0.2\n",
    "\n",
    "for a in os.listdir(path_dog):\n",
    "    total_img_num += len(os.listdir(os.path.join(path_dog, a)))\n",
    "\n",
    "for a in os.listdir(path_nodog):\n",
    "    total_img_num += len(os.listdir(os.path.join(path_nodog, a)))\n",
    "\n",
    "total_val = total_img_num * split\n",
    "total_train = total_img_num - total_val\n",
    "\n",
    "print('total images:', total_img_num)\n",
    "print('number of training data:', total_train)\n",
    "print('number of validation:', total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 26\n",
    "IMG_HEIGHT = 112\n",
    "IMG_WIDTH = 112\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 25529 images belonging to 2 classes.\nFound 6382 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,rotation_range=40, # Angle, 0-180\n",
    "    width_shift_range=0.2, # horizontal shifting\n",
    "    height_shift_range=0.2, # vertical shifting\n",
    "    shear_range=0.2, # Shearing\n",
    "    zoom_range=0.2, # Zooming\n",
    "    horizontal_flip=True, # Flipping\n",
    "    validation_split=split\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ") # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ") # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all labels\n",
    "labels = train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'cat': 0, 'no_cat': 1}\n"
    }
   ],
   "source": [
    "## check encoded label\n",
    "labels = (train_generator.class_indices)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\cs623\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\nWARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\nWARNING:tensorflow:From C:\\Users\\cs623\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.8),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.8),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/26\n13/99 [==>...........................] - ETA: 2:24 - loss: 0.8294 - acc: 0.4958C:\\Users\\cs623\\Anaconda3\\envs\\py36\\lib\\site-packages\\PIL\\Image.py:989: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n99/99 [==============================] - 190s 2s/step - loss: 0.6745 - acc: 0.6015 - val_loss: 0.6946 - val_acc: 0.5454\nEpoch 2/26\n99/99 [==============================] - 186s 2s/step - loss: 0.6107 - acc: 0.6780 - val_loss: 0.7009 - val_acc: 0.5498\nEpoch 3/26\n99/99 [==============================] - 187s 2s/step - loss: 0.5935 - acc: 0.6917 - val_loss: 0.6837 - val_acc: 0.6047\nEpoch 4/26\n99/99 [==============================] - 189s 2s/step - loss: 0.5824 - acc: 0.6971 - val_loss: 0.7232 - val_acc: 0.5648\nEpoch 5/26\n14/99 [===>..........................] - ETA: 1:42 - loss: 0.5865 - acc: 0.6953"
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = total_train // batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = total_val // batch_size \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model.save(\"Detection.h5\")\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Detection_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}