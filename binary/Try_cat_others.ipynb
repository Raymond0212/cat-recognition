{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.optimizers as opt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, MaxPooling1D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "    code from http://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "    \"\"\"\n",
    "    from tensorflow.python.client import device_lib as _device_lib\n",
    "    local_device_protos = _device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU' or x.device_type == 'CPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['/device:CPU:0']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path & total number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/users/cs623/.keras/datasets/personal_cats_and_dogs\"\n",
    "path_cat = os.path.join(path, 'cats')\n",
    "path_dog = os.path.join(path, 'dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "all kinds of cats:  ['喜马拉雅猫', '奶牛猫', '孟买猫', '布偶猫', '扁脸加菲猫', '折耳猫', '暹罗猫', '橘猫', '玫瑰纹豹猫', '缅因猫', '美短', '芬克斯猫', '蓝猫', '金渐层', '银渐层']\n喜马拉雅猫 :  700\n奶牛猫 :  1043\n孟买猫 :  1100\n布偶猫 :  1113\n扁脸加菲猫 :  1311\n折耳猫 :  1084\n暹罗猫 :  1260\n橘猫 :  1380\n玫瑰纹豹猫 :  780\n缅因猫 :  1065\n美短 :  863\n芬克斯猫 :  911\n蓝猫 :  1200\n金渐层 :  1362\n银渐层 :  1361\ntotal cat imgs:  16533\n"
    }
   ],
   "source": [
    "num_cats = len(os.listdir(path_cat))\n",
    "num_dogs = len(os.listdir(path_dog))\n",
    "total_img_num = num_cats + num_dogs\n",
    "print('total cat images:', num_cats)\n",
    "print('total dog images:', num_dogs)\n",
    "print('total images:', total_img_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "split = 0.2\n",
    "total_val = total_img_num * split\n",
    "total_train = total_img_num - total_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,rotation_range=40, # Angle, 0-180\n",
    "    width_shift_range=0.2, # horizontal shifting\n",
    "    height_shift_range=0.2, # vertical shifting\n",
    "    shear_range=0.2, # Shearing\n",
    "    zoom_range=0.2, # Zooming\n",
    "    horizontal_flip=True, # Flipping\n",
    "    validation_split=split\n",
    ")\n",
    "\n",
    "#    shear_range=0.2,\n",
    "#    zoom_range=0.2,\n",
    "#    horizontal_flip=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 13230 images belonging to 15 classes.\nFound 3303 images belonging to 15 classes.\n"
    }
   ],
   "source": [
    "# Load images from the disk, applies rescaling, and resizes the images\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def count_label(generator):\n",
    "    l = len(generator)\n",
    "    counter = collections.Counter()\n",
    "    for i in range(l):\n",
    "        _, label = generator[i]\n",
    "        unique, counts = np.unique(label, return_counts=True)\n",
    "        count_label = dict(zip(unique, counts))\n",
    "        counter.update(count_label) \n",
    "    result = dict(counter)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_count = count_label(train_generator)\n",
    "# val_count = count_label(validation_generator)\n",
    "\n",
    "# print(\"Training labels:\")\n",
    "# print(train_count)\n",
    "# print(\"Validation labels:\")\n",
    "# print(val_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_train, sample_label_train = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImg(img):\n",
    "    fig, axes = plt.subplots(3, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for i, a in zip(img, axes):\n",
    "        a.imshow(i)\n",
    "        a.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotImg(sample_img_train[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\cs623\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
    }
   ],
   "source": [
    "VGGNet = Sequential([\n",
    "    Conv2D(64, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(256, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    # Conv2D(512, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\cs623\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# lr_base = 0.001\n",
    "# epochs = 250\n",
    "# lr_power = 0.9\n",
    "# def lr_scheduler(epoch, mode='power_decay'):\n",
    "#     '''if lr_dict.has_key(epoch):\n",
    "#         lr = lr_dict[epoch]\n",
    "#         print 'lr: %f' % lr'''\n",
    " \n",
    "#     if mode is 'power_decay':\n",
    "#         # original lr scheduler\n",
    "#         lr = lr_base * ((1 - float(epoch) / epochs) ** lr_power)\n",
    "#     if mode is 'exp_decay':\n",
    "#         # exponential decay\n",
    "#         lr = (float(lr_base) ** float(lr_power)) ** float(epoch + 1)\n",
    "#     # adam default lr\n",
    "#     if mode is 'adam':\n",
    "#         lr = 0.001\n",
    " \n",
    "#     if mode is 'progressive_drops':\n",
    "#         # drops as progression proceeds, good for sgd\n",
    "#         if epoch > 0.9 * epochs:\n",
    "#             lr = 0.0001\n",
    "#         elif epoch > 0.75 * epochs:\n",
    "#             lr = 0.001\n",
    "#         elif epoch > 0.5 * epochs:\n",
    "#             lr = 0.01\n",
    "#         else:\n",
    "#             lr = 0.1\n",
    " \n",
    "#     print('lr: %f' % lr)\n",
    "#     return lr\n",
    " \n",
    "# # 学习率调度器\n",
    "# scheduler = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = opt.SGD(lr=1e-1, decay=1e-6, momentum=0.8, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,\n",
    "             loss='mean_squared_error',\n",
    "             metrics=['accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 150, 150, 16)      448       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 150, 150, 16)      2320      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 75, 75, 32)        4640      \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 75, 75, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 38, 38, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 38, 38, 64)        18496     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 38, 38, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 19, 19, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 23104)             0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               11829760  \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 11,902,353\nTrainable params: 11,902,353\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# config = tf.ConfigProto()  \n",
    "# config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "# session = tf.Session(config=config)\n",
    "\n",
    "# # 设置session\n",
    "# KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1/30\n"
    },
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (128, 15) was passed for an output of shape (None, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-26fa878a0162>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_val\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1151\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m   1152\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \u001b[1;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2690\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2692\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    547\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    548\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (128, 15) was passed for an output of shape (None, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  \n",
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = total_train // batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = total_val // batch_size     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}